# NASA Space Apps Challenge 2019
## 3rd place + Best use of hardware awards

Nasa's space apps challenge, celebrated in Hong Kong for the first time in the contest history. 

### Contest location
- City University of Hong Kong, October 2019

More info at [Nestor Sabater's portfolio](https://nsabater.com/nasa-space-apps-challenge-2019-3rd-place-award)

Developed with Unreal Engine 4 + Leap Motion
By [Nestor Sabater](https://nsabater.com)
and [Marcos Urios](https://marcosurios.com)

------------

Assets used:
- Astronaut + Habitat: [Nasa 3d model respository](https://nasa3d.arc.nasa.gov/models)
- L.R.V. vehicle: Unreal Engine default test vehicle

The rest of the models and environments have been developed by the team itself.

------------------------------------------  

### Demonstration video

[Youtube demo video](https://www.youtube.com/watch?v=2ytr35p4DNo)  

[![Video preview 1](https://j.gifs.com/ANk7j7.gif)](https://www.youtube.com/watch?v=2ytr35p4DNo)

[![Video preview 2](https://j.gifs.com/lx4mQ7.gif)](https://www.youtube.com/watch?v=2ytr35p4DNo)


### Environment screenshot
![](https://nsabater.com/wp-content/uploads/2019/10/Screenshot_44-1024x556.png)

### The idea  
The idea behind the project is to experiment and showcase with new types of interactions. We choosed astronauts as it may be more usefull to them, but this could be used for heavy machinery or ingeneering positions aswell.

This interactions can be actually be performed in the real world, thanks to Machine Learning and Deep learning to recognice things, plug a set of devices like leap motion, project north star and some other cameras for deph checking, capturing and recognition.

You can read more about this kind of setups here: [Project north star blog](http://blog.leapmotion.com/north-star-open-source/)


![](https://github.com/nesjett/NASA-SpaceAppChallenge2019/blob/master/descarga%20(3).png?raw=true)


### Winning photo
![](https://nsabater.com/wp-content/uploads/2019/10/1020_4-min-1024x768.jpg)
